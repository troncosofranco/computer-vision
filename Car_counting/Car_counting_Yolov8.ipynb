{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61d7349b2b7f4426bdefb2ae1b845ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33fe2396cb7746dba002d69d3448daef",
              "IPY_MODEL_a3faac88aa99461aa4063e27795aae1a",
              "IPY_MODEL_6a55a2131b794788b47b20a839dad499"
            ],
            "layout": "IPY_MODEL_ec5cd493645d4a6f8c5a15824b4a43fd"
          }
        },
        "33fe2396cb7746dba002d69d3448daef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08f89039f3154bb09b584c4d8ddbf148",
            "placeholder": "​",
            "style": "IPY_MODEL_29a53c7316ec482b82b8a02a74955a50",
            "value": "100%"
          }
        },
        "a3faac88aa99461aa4063e27795aae1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b1b078e2a844c34ad954cdce768ec40",
            "max": 136867539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d529d94960114ee7a1e98bac3509d9de",
            "value": 136867539
          }
        },
        "6a55a2131b794788b47b20a839dad499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_599fe23cc6af44b48b595081962eead3",
            "placeholder": "​",
            "style": "IPY_MODEL_06fa44de86fa4d639c0b8e7ead50d3f9",
            "value": " 131M/131M [00:00&lt;00:00, 216MB/s]"
          }
        },
        "ec5cd493645d4a6f8c5a15824b4a43fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f89039f3154bb09b584c4d8ddbf148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a53c7316ec482b82b8a02a74955a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b1b078e2a844c34ad954cdce768ec40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d529d94960114ee7a1e98bac3509d9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "599fe23cc6af44b48b595081962eead3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06fa44de86fa4d639c0b8e7ead50d3f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de460459b9194144aa4b4db78c9372ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f00264cbfd1246e49933255d3392ae5c",
              "IPY_MODEL_32294204fcdd460d87dde2c67e008de3",
              "IPY_MODEL_6f14a03726b844b080f0d01acb1647a8"
            ],
            "layout": "IPY_MODEL_5143e82bd8064999b1720c31a87e278c"
          }
        },
        "f00264cbfd1246e49933255d3392ae5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e81fe738c6584908babcd4159edfc63d",
            "placeholder": "​",
            "style": "IPY_MODEL_70f4737a3df94f1ba53a78799f8d3edc",
            "value": "100%"
          }
        },
        "32294204fcdd460d87dde2c67e008de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_050f3aa0bb1f4bc88f8cc25684099c6c",
            "max": 946,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4de81ad93fb54fc08d5f040861a0fa56",
            "value": 946
          }
        },
        "6f14a03726b844b080f0d01acb1647a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b56500f8969471b957ed29bfc26793b",
            "placeholder": "​",
            "style": "IPY_MODEL_faf7fdd3764344e7855650c9eacea5f0",
            "value": " 946/946 [00:58&lt;00:00, 16.74it/s]"
          }
        },
        "5143e82bd8064999b1720c31a87e278c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81fe738c6584908babcd4159edfc63d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f4737a3df94f1ba53a78799f8d3edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "050f3aa0bb1f4bc88f8cc25684099c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de81ad93fb54fc08d5f040861a0fa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b56500f8969471b957ed29bfc26793b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf7fdd3764344e7855650c9eacea5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##0. Introduction\n",
        "\n",
        "In this notebook the car counting using Yolow8 is performed. The objective is the accurate counting in city streets in order to  introduce improvements in traffic management. "
      ],
      "metadata": {
        "id": "-yPW73J8wVkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. GPU Environment"
      ],
      "metadata": {
        "id": "R7boPKtuxHG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access to GPU"
      ],
      "metadata": {
        "id": "i6YAlszoxKF7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-08iE1tv_jj",
        "outputId": "8e370f3e-ba2f-4f7a-e13c-792f345d7911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 15 22:57:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    32W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKmLLVdVxOlg",
        "outputId": "c5984453-8046-40df-c35d-040b9094f26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Load video"
      ],
      "metadata": {
        "id": "lw9IULdWybrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd {HOME}\n",
        "#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt\n",
        "SOURCE_VIDEO_PATH = f\"{HOME}/car_counting.mp4\"\n",
        "#SOURCE_VIDEO_PATH = f\"{HOME}/vehicle-counting.mp4\""
      ],
      "metadata": {
        "id": "t9tjsuYeyUT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Install YOLOv8"
      ],
      "metadata": {
        "id": "SGkrSJX20VoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-p0cuEk0aV_",
        "outputId": "0c4328a8-45e7-4e66-ab59-3112a4824d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.53 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 25.5/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Install ByteTrack"
      ],
      "metadata": {
        "id": "aZBpoaRP0i3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "!cd ByteTrack && pip3 install -q -r requirements.txt\n",
        "!cd ByteTrack && python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "!pip install loguru\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD53z5uv0iio",
        "outputId": "7ac8b6a4-ac7d-4ccf-eb07-ddd4d3733a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting loguru\n",
            "  Using cached loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: loguru\n",
            "Successfully installed loguru-0.6.0\n",
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lap\n",
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6842z0SL0s2j",
        "outputId": "25acde99-acbe-4de4-d777-8b549097ca98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lap\n",
            "  Using cached lap-0.4.0-cp39-cp39-linux_x86_64.whl\n",
            "Installing collected packages: lap\n",
            "Successfully installed lap-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Install Supervision"
      ],
      "metadata": {
        "id": "hhxr7OVJ1KGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPOH8WLG1Pqk",
        "outputId": "641185a6-fe5e-46b7-9ff5-56188d4e03d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supervision.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ],
      "metadata": {
        "id": "UT0nUIb21SXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Install tracking utils"
      ],
      "metadata": {
        "id": "IyyTuCj-1ZK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "# converts detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections, \n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "    \n",
        "    tracker_ids = [None] * len(detections)\n",
        "    \n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "Qcz_AD061WUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Load pre-trained YOLOv8 model"
      ],
      "metadata": {
        "id": "9nC6GlIy2ht3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"yolov8x.pt\"\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "61d7349b2b7f4426bdefb2ae1b845ff8",
            "33fe2396cb7746dba002d69d3448daef",
            "a3faac88aa99461aa4063e27795aae1a",
            "6a55a2131b794788b47b20a839dad499",
            "ec5cd493645d4a6f8c5a15824b4a43fd",
            "08f89039f3154bb09b584c4d8ddbf148",
            "29a53c7316ec482b82b8a02a74955a50",
            "9b1b078e2a844c34ad954cdce768ec40",
            "d529d94960114ee7a1e98bac3509d9de",
            "599fe23cc6af44b48b595081962eead3",
            "06fa44de86fa4d639c0b8e7ead50d3f9"
          ]
        },
        "id": "KXJdqzaF2m0N",
        "outputId": "f0d60761-5ff8-483a-d408-bf8b768c5068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt to yolov8x.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/131M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d7349b2b7f4426bdefb2ae1b845ff8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Prediction categories (single frame)"
      ],
      "metadata": {
        "id": "caT7wxUC2uTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [2, 3, 5, 7]"
      ],
      "metadata": {
        "id": "Mj6T1rsB2xgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model(frame)\n",
        "detections = Detections(\n",
        "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        ")\n",
        "\n",
        "# format custom labels\n",
        "labels = [\n",
        "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "    for _, confidence, class_id, tracker_id\n",
        "    in detections\n",
        "]\n",
        "\n",
        "# annotate and display frame\n",
        "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "show_frame_in_notebook(frame, (16, 16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df8WtbQj2o32",
        "outputId": "6fd48ff0-b31c-4b87-eb79-8b6676f272a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 bus, 61.7ms\n",
            "Speed: 0.5ms preprocess, 61.7ms inference, 22.9ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Predict the whole video"
      ],
      "metadata": {
        "id": "49OJ_cL83Til"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "LINE_START = Point(820, 610)\n",
        "LINE_END = Point(600, 400)\n",
        "\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/vehicle-counting-result.mp4\""
      ],
      "metadata": {
        "id": "1nKPhhw63RyL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlHdb7Do3cl4",
        "outputId": "f4b41967-280d-4f3a-a921-b1a1727f8f59"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VideoInfo(width=1092, height=614, fps=30, total_frames=946)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# create BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "\n",
        "# create VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create LineCounter instance\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "\n",
        "# create instance of BoxAnnotator and LineCounterAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "    for frame in tqdm(generator, total=video_info.total_frames):\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        # filtering out detections with unwanted classes\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # tracking detections\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        # filtering out detections without trackers\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # format custom labels\n",
        "        labels = [\n",
        "           # f\"#{CLASS_NAMES_DICT[class_id]}\"\n",
        "            #for _, confidence, class_id, tracker_id\n",
        "            #in detections\n",
        "        ]\n",
        "        # updating line counter\n",
        "        line_counter.update(detections=detections)\n",
        "        # annotate and display frame\n",
        "        #frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "        sink.write_frame(frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de460459b9194144aa4b4db78c9372ba",
            "f00264cbfd1246e49933255d3392ae5c",
            "32294204fcdd460d87dde2c67e008de3",
            "6f14a03726b844b080f0d01acb1647a8",
            "5143e82bd8064999b1720c31a87e278c",
            "e81fe738c6584908babcd4159edfc63d",
            "70f4737a3df94f1ba53a78799f8d3edc",
            "050f3aa0bb1f4bc88f8cc25684099c6c",
            "4de81ad93fb54fc08d5f040861a0fa56",
            "3b56500f8969471b957ed29bfc26793b",
            "faf7fdd3764344e7855650c9eacea5f0"
          ]
        },
        "id": "aOJRnYPO3dBq",
        "outputId": "72ef60ea-e622-40e4-fec3-3435721f7898"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/946 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de460459b9194144aa4b4db78c9372ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 bus, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 bus, 64.5ms\n",
            "Speed: 0.9ms preprocess, 64.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 bus, 45.5ms\n",
            "Speed: 0.5ms preprocess, 45.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 43.1ms\n",
            "Speed: 0.4ms preprocess, 43.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 43.2ms\n",
            "Speed: 0.7ms preprocess, 43.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 30.2ms\n",
            "Speed: 0.5ms preprocess, 30.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 bus, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 31.5ms\n",
            "Speed: 0.5ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 31.5ms\n",
            "Speed: 0.4ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 31.8ms\n",
            "Speed: 0.4ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 bus, 31.3ms\n",
            "Speed: 0.4ms preprocess, 31.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 bus, 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 bus, 31.7ms\n",
            "Speed: 0.4ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9 cars, 1 bus, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9 cars, 1 bus, 33.4ms\n",
            "Speed: 0.8ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 1 bus, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 33.3ms\n",
            "Speed: 0.8ms preprocess, 33.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 31.5ms\n",
            "Speed: 0.4ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 bus, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 bus, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 bus, 43.2ms\n",
            "Speed: 0.5ms preprocess, 43.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 31.8ms\n",
            "Speed: 0.8ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 bus, 31.4ms\n",
            "Speed: 0.4ms preprocess, 31.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 31.8ms\n",
            "Speed: 0.4ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 32.6ms\n",
            "Speed: 0.6ms preprocess, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 31.4ms\n",
            "Speed: 0.4ms preprocess, 31.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 31.9ms\n",
            "Speed: 0.4ms preprocess, 31.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 32.0ms\n",
            "Speed: 0.4ms preprocess, 32.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 31.9ms\n",
            "Speed: 0.4ms preprocess, 31.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 32.9ms\n",
            "Speed: 0.6ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 1 bus, 33.1ms\n",
            "Speed: 0.7ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 bus, 32.1ms\n",
            "Speed: 0.7ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 31.9ms\n",
            "Speed: 0.4ms preprocess, 31.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 34.4ms\n",
            "Speed: 0.3ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 32.2ms\n",
            "Speed: 0.6ms preprocess, 32.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.2ms\n",
            "Speed: 0.7ms preprocess, 33.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 1 bus, 31.9ms\n",
            "Speed: 0.4ms preprocess, 31.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 33.4ms\n",
            "Speed: 0.6ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 32.3ms\n",
            "Speed: 0.6ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 33.1ms\n",
            "Speed: 0.7ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 32.4ms\n",
            "Speed: 0.6ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 32.5ms\n",
            "Speed: 0.4ms preprocess, 32.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 33.5ms\n",
            "Speed: 0.3ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 32.9ms\n",
            "Speed: 0.3ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.0ms\n",
            "Speed: 0.7ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 33.6ms\n",
            "Speed: 0.3ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 umbrella, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 umbrella, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 umbrella, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.4ms\n",
            "Speed: 0.3ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.6ms\n",
            "Speed: 0.3ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 motorcycle, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.8ms\n",
            "Speed: 0.3ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 37.4ms\n",
            "Speed: 0.4ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.3ms\n",
            "Speed: 0.6ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.1ms\n",
            "Speed: 0.3ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 motorcycle, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 motorcycle, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.5ms\n",
            "Speed: 0.6ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.0ms\n",
            "Speed: 0.3ms preprocess, 34.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.0ms\n",
            "Speed: 0.3ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 33.4ms\n",
            "Speed: 0.7ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.5ms\n",
            "Speed: 0.6ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.0ms\n",
            "Speed: 0.3ms preprocess, 34.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 truck, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 33.6ms\n",
            "Speed: 0.7ms preprocess, 33.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 32.5ms\n",
            "Speed: 0.4ms preprocess, 32.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 34.1ms\n",
            "Speed: 0.3ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 34.6ms\n",
            "Speed: 0.6ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.4ms\n",
            "Speed: 0.7ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.2ms\n",
            "Speed: 0.3ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.6ms\n",
            "Speed: 0.4ms preprocess, 34.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 truck, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.5ms\n",
            "Speed: 0.6ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.5ms\n",
            "Speed: 0.8ms preprocess, 33.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.6ms\n",
            "Speed: 0.6ms preprocess, 34.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 36.6ms\n",
            "Speed: 0.4ms preprocess, 36.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 31.7ms\n",
            "Speed: 0.5ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 31.1ms\n",
            "Speed: 0.5ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 35.1ms\n",
            "Speed: 0.6ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 31.0ms\n",
            "Speed: 0.5ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 2 buss, 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 2 buss, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 2 buss, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 32.2ms\n",
            "Speed: 1.4ms preprocess, 32.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 buss, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 bus, 36.3ms\n",
            "Speed: 0.5ms preprocess, 36.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 31.6ms\n",
            "Speed: 1.9ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 truck, 31.9ms\n",
            "Speed: 1.9ms preprocess, 31.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 31.6ms\n",
            "Speed: 0.5ms preprocess, 31.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 32.3ms\n",
            "Speed: 0.8ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 31.6ms\n",
            "Speed: 0.5ms preprocess, 31.6ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 32.3ms\n",
            "Speed: 0.5ms preprocess, 32.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 32.5ms\n",
            "Speed: 1.3ms preprocess, 32.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 36.2ms\n",
            "Speed: 0.4ms preprocess, 36.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12 cars, 3 buss, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12 cars, 3 buss, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12 cars, 3 buss, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 33.9ms\n",
            "Speed: 0.6ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.2ms\n",
            "Speed: 0.7ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.0ms\n",
            "Speed: 0.7ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.6ms\n",
            "Speed: 0.4ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.5ms\n",
            "Speed: 0.3ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 36.1ms\n",
            "Speed: 0.5ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 truck, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 truck, 33.4ms\n",
            "Speed: 1.0ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 truck, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 truck, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 truck, 38.1ms\n",
            "Speed: 0.3ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 1 truck, 35.1ms\n",
            "Speed: 0.5ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 truck, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 truck, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 truck, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 35.8ms\n",
            "Speed: 0.4ms preprocess, 35.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 truck, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 truck, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 34.2ms\n",
            "Speed: 0.6ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 33.0ms\n",
            "Speed: 2.0ms preprocess, 33.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 34.6ms\n",
            "Speed: 0.6ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 33.9ms\n",
            "Speed: 0.3ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 34.3ms\n",
            "Speed: 0.7ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 34.9ms\n",
            "Speed: 0.7ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 33.5ms\n",
            "Speed: 0.3ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 34.6ms\n",
            "Speed: 0.3ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 1 bus, 1 truck, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 1 bus, 1 truck, 33.0ms\n",
            "Speed: 0.7ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 1 truck, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 2 buss, 1 truck, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 2 buss, 1 truck, 35.1ms\n",
            "Speed: 0.3ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 2 buss, 1 truck, 33.9ms\n",
            "Speed: 0.3ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 2 buss, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 2 buss, 33.7ms\n",
            "Speed: 0.6ms preprocess, 33.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 2 buss, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 32.5ms\n",
            "Speed: 0.7ms preprocess, 32.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 32.0ms\n",
            "Speed: 0.4ms preprocess, 32.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 34.2ms\n",
            "Speed: 0.3ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 35.1ms\n",
            "Speed: 0.5ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 34.3ms\n",
            "Speed: 0.3ms preprocess, 34.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 34.6ms\n",
            "Speed: 0.4ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 35.3ms\n",
            "Speed: 0.4ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 35.2ms\n",
            "Speed: 0.9ms preprocess, 35.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 35.3ms\n",
            "Speed: 0.4ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.7ms\n",
            "Speed: 0.3ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 33.4ms\n",
            "Speed: 0.6ms preprocess, 33.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 34.8ms\n",
            "Speed: 0.7ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 36.0ms\n",
            "Speed: 1.6ms preprocess, 36.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 2 buss, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 2 buss, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.9ms\n",
            "Speed: 0.3ms preprocess, 33.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 34.1ms\n",
            "Speed: 0.6ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 3 buss, 1 truck, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 buss, 1 truck, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 buss, 1 truck, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 buss, 1 truck, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 35.4ms\n",
            "Speed: 0.3ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 truck, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.8ms\n",
            "Speed: 0.6ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.3ms\n",
            "Speed: 0.7ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 35.2ms\n",
            "Speed: 0.6ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 truck, 35.5ms\n",
            "Speed: 0.4ms preprocess, 35.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.9ms\n",
            "Speed: 0.4ms preprocess, 35.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.4ms\n",
            "Speed: 0.6ms preprocess, 32.4ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.6ms\n",
            "Speed: 0.6ms preprocess, 34.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 1 traffic light, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 41.3ms\n",
            "Speed: 0.6ms preprocess, 41.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.7ms\n",
            "Speed: 0.9ms preprocess, 32.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.6ms\n",
            "Speed: 0.8ms preprocess, 32.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 31.7ms\n",
            "Speed: 0.6ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 32.5ms\n",
            "Speed: 0.4ms preprocess, 32.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.0ms\n",
            "Speed: 0.4ms preprocess, 32.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 30.8ms\n",
            "Speed: 0.6ms preprocess, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.4ms\n",
            "Speed: 0.6ms preprocess, 32.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 41.8ms\n",
            "Speed: 0.8ms preprocess, 41.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.1ms\n",
            "Speed: 0.5ms preprocess, 32.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 38.1ms\n",
            "Speed: 0.5ms preprocess, 38.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.6ms\n",
            "Speed: 0.4ms preprocess, 34.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.2ms\n",
            "Speed: 0.5ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.7ms\n",
            "Speed: 0.5ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 35.2ms\n",
            "Speed: 0.5ms preprocess, 35.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 35.7ms\n",
            "Speed: 0.4ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.7ms\n",
            "Speed: 0.6ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 38.5ms\n",
            "Speed: 0.3ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 31.1ms\n",
            "Speed: 0.4ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.2ms\n",
            "Speed: 0.5ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.2ms\n",
            "Speed: 0.8ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 36.5ms\n",
            "Speed: 0.5ms preprocess, 36.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 33.4ms\n",
            "Speed: 0.6ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 35.7ms\n",
            "Speed: 0.4ms preprocess, 35.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 34.4ms\n",
            "Speed: 0.8ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 35.4ms\n",
            "Speed: 0.4ms preprocess, 35.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 35.3ms\n",
            "Speed: 0.4ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.6ms\n",
            "Speed: 0.4ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 35.9ms\n",
            "Speed: 0.4ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 cars, 35.6ms\n",
            "Speed: 0.5ms preprocess, 35.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 34.8ms\n",
            "Speed: 0.5ms preprocess, 34.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 cars, 36.0ms\n",
            "Speed: 1.1ms preprocess, 36.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.1ms\n",
            "Speed: 0.5ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.5ms\n",
            "Speed: 0.4ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.7ms\n",
            "Speed: 0.4ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 35.4ms\n",
            "Speed: 0.6ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.6ms\n",
            "Speed: 0.4ms preprocess, 35.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.7ms\n",
            "Speed: 0.5ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.0ms\n",
            "Speed: 0.6ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.3ms\n",
            "Speed: 0.4ms preprocess, 35.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.4ms\n",
            "Speed: 0.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.4ms\n",
            "Speed: 0.3ms preprocess, 33.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 32.4ms\n",
            "Speed: 0.7ms preprocess, 32.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.4ms\n",
            "Speed: 0.6ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.5ms\n",
            "Speed: 0.4ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 cars, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 cars, 33.9ms\n",
            "Speed: 0.6ms preprocess, 33.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 cars, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 16 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 truck, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.4ms\n",
            "Speed: 0.4ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.3ms\n",
            "Speed: 0.4ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 35.2ms\n",
            "Speed: 0.3ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 35.4ms\n",
            "Speed: 0.4ms preprocess, 35.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 cars, 35.7ms\n",
            "Speed: 0.4ms preprocess, 35.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 35.3ms\n",
            "Speed: 0.5ms preprocess, 35.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 35.3ms\n",
            "Speed: 0.4ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 35.9ms\n",
            "Speed: 0.4ms preprocess, 35.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.3ms\n",
            "Speed: 0.6ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 33.0ms\n",
            "Speed: 0.7ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 truck, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 33.0ms\n",
            "Speed: 2.2ms preprocess, 33.0ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 42.8ms\n",
            "Speed: 0.5ms preprocess, 42.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 35.4ms\n",
            "Speed: 0.4ms preprocess, 35.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 31.8ms\n",
            "Speed: 0.5ms preprocess, 31.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 cars, 32.5ms\n",
            "Speed: 0.4ms preprocess, 32.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 7 cars, 33.1ms\n",
            "Speed: 1.2ms preprocess, 33.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 34.2ms\n",
            "Speed: 0.7ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 35.7ms\n",
            "Speed: 0.4ms preprocess, 35.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 35.8ms\n",
            "Speed: 0.4ms preprocess, 35.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 33.3ms\n",
            "Speed: 0.5ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 32.9ms\n",
            "Speed: 0.5ms preprocess, 32.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 31.7ms\n",
            "Speed: 1.8ms preprocess, 31.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.0ms\n",
            "Speed: 0.5ms preprocess, 32.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 34.0ms\n",
            "Speed: 0.6ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 33.7ms\n",
            "Speed: 0.5ms preprocess, 33.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 34.6ms\n",
            "Speed: 2.0ms preprocess, 34.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 32.2ms\n",
            "Speed: 0.5ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.9ms\n",
            "Speed: 0.5ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.7ms\n",
            "Speed: 0.4ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 34.7ms\n",
            "Speed: 0.3ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 35.5ms\n",
            "Speed: 0.4ms preprocess, 35.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.8ms\n",
            "Speed: 0.7ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.5ms\n",
            "Speed: 0.5ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 39.5ms\n",
            "Speed: 0.5ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 31.5ms\n",
            "Speed: 0.4ms preprocess, 31.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 41.0ms\n",
            "Speed: 0.5ms preprocess, 41.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 40.5ms\n",
            "Speed: 0.4ms preprocess, 40.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 44.9ms\n",
            "Speed: 0.5ms preprocess, 44.9ms inference, 9.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 61.9ms\n",
            "Speed: 2.0ms preprocess, 61.9ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 30.1ms\n",
            "Speed: 0.4ms preprocess, 30.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 32.3ms\n",
            "Speed: 0.8ms preprocess, 32.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 36.7ms\n",
            "Speed: 0.8ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 33.7ms\n",
            "Speed: 0.7ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 35.0ms\n",
            "Speed: 0.5ms preprocess, 35.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.1ms\n",
            "Speed: 0.3ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.6ms\n",
            "Speed: 0.5ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 33.1ms\n",
            "Speed: 0.7ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 33.4ms\n",
            "Speed: 0.7ms preprocess, 33.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 35.6ms\n",
            "Speed: 1.4ms preprocess, 35.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 32.8ms\n",
            "Speed: 2.4ms preprocess, 32.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 34.4ms\n",
            "Speed: 0.5ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 34.2ms\n",
            "Speed: 0.4ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.4ms\n",
            "Speed: 0.6ms preprocess, 32.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 35.0ms\n",
            "Speed: 0.4ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 34.2ms\n",
            "Speed: 0.5ms preprocess, 34.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 33.8ms\n",
            "Speed: 0.6ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.9ms\n",
            "Speed: 0.6ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 34.4ms\n",
            "Speed: 0.6ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 2 buss, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 34.3ms\n",
            "Speed: 0.5ms preprocess, 34.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 32.8ms\n",
            "Speed: 0.4ms preprocess, 32.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 2 buss, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 2 buss, 37.4ms\n",
            "Speed: 0.4ms preprocess, 37.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 2 buss, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 2 buss, 33.4ms\n",
            "Speed: 1.2ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 33.7ms\n",
            "Speed: 0.7ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 3 buss, 34.0ms\n",
            "Speed: 0.4ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 3 buss, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 3 buss, 34.2ms\n",
            "Speed: 2.1ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 3 buss, 36.8ms\n",
            "Speed: 0.4ms preprocess, 36.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 3 buss, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 3 buss, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 3 buss, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 3 buss, 32.3ms\n",
            "Speed: 0.7ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 3 buss, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 3 buss, 34.1ms\n",
            "Speed: 0.5ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 3 buss, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 3 buss, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 33.6ms\n",
            "Speed: 0.3ms preprocess, 33.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 buss, 33.3ms\n",
            "Speed: 0.6ms preprocess, 33.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 2 buss, 32.5ms\n",
            "Speed: 0.4ms preprocess, 32.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 2 buss, 33.7ms\n",
            "Speed: 0.4ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 2 buss, 33.5ms\n",
            "Speed: 2.1ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 35.9ms\n",
            "Speed: 0.5ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 1 bus, 31.7ms\n",
            "Speed: 0.5ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 1 bus, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 1 bus, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 2 buss, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 33.9ms\n",
            "Speed: 0.5ms preprocess, 33.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 3 buss, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 3 buss, 34.6ms\n",
            "Speed: 0.4ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 3 buss, 31.6ms\n",
            "Speed: 0.4ms preprocess, 31.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 1 bus, 1 truck, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 truck, 32.5ms\n",
            "Speed: 0.4ms preprocess, 32.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12 cars, 1 truck, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 1 bus, 1 truck, 35.2ms\n",
            "Speed: 0.5ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 1 truck, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12 cars, 1 bus, 1 truck, 31.7ms\n",
            "Speed: 0.4ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 1 bus, 1 truck, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 1 bus, 1 truck, 34.3ms\n",
            "Speed: 0.4ms preprocess, 34.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9 cars, 1 bus, 35.2ms\n",
            "Speed: 0.4ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 2 buss, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 2 buss, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 2 buss, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 1 bus, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 1 bus, 33.9ms\n",
            "Speed: 0.4ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9 cars, 1 bus, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9 cars, 34.6ms\n",
            "Speed: 0.5ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9 cars, 34.9ms\n",
            "Speed: 0.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9 cars, 34.5ms\n",
            "Speed: 0.4ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 truck, 33.8ms\n",
            "Speed: 0.5ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 truck, 35.8ms\n",
            "Speed: 0.4ms preprocess, 35.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 32.4ms\n",
            "Speed: 0.8ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 truck, 33.4ms\n",
            "Speed: 0.5ms preprocess, 33.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 31.7ms\n",
            "Speed: 0.6ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 33.3ms\n",
            "Speed: 0.9ms preprocess, 33.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 35.1ms\n",
            "Speed: 0.4ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 35.1ms\n",
            "Speed: 0.5ms preprocess, 35.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 31.4ms\n",
            "Speed: 0.5ms preprocess, 31.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 34.0ms\n",
            "Speed: 0.5ms preprocess, 34.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 45.3ms\n",
            "Speed: 0.4ms preprocess, 45.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 74.2ms\n",
            "Speed: 0.5ms preprocess, 74.2ms inference, 17.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 55.4ms\n",
            "Speed: 8.6ms preprocess, 55.4ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 62.7ms\n",
            "Speed: 5.5ms preprocess, 62.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 85.6ms\n",
            "Speed: 0.5ms preprocess, 85.6ms inference, 9.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 107.1ms\n",
            "Speed: 0.7ms preprocess, 107.1ms inference, 9.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 38.0ms\n",
            "Speed: 1.9ms preprocess, 38.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 1 truck, 31.9ms\n",
            "Speed: 0.4ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 1 truck, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 1 truck, 33.3ms\n",
            "Speed: 0.4ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 33.2ms\n",
            "Speed: 0.7ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 31.2ms\n",
            "Speed: 0.5ms preprocess, 31.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 33.4ms\n",
            "Speed: 0.4ms preprocess, 33.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 93.4ms\n",
            "Speed: 0.5ms preprocess, 93.4ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 115.9ms\n",
            "Speed: 0.5ms preprocess, 115.9ms inference, 18.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 96.1ms\n",
            "Speed: 17.6ms preprocess, 96.1ms inference, 10.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 motorcycle, 1 truck, 64.3ms\n",
            "Speed: 9.3ms preprocess, 64.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 31.0ms\n",
            "Speed: 0.7ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 motorcycle, 1 truck, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 truck, 39.4ms\n",
            "Speed: 0.5ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 1 truck, 31.5ms\n",
            "Speed: 0.5ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 10 cars, 1 truck, 33.5ms\n",
            "Speed: 0.5ms preprocess, 33.5ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 1 truck, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 8 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 32.6ms\n",
            "Speed: 0.5ms preprocess, 32.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 9 cars, 33.1ms\n",
            "Speed: 0.5ms preprocess, 33.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 32.5ms\n",
            "Speed: 0.5ms preprocess, 32.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 31.8ms\n",
            "Speed: 1.9ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 11 cars, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 motorcycle, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 motorcycle, 33.6ms\n",
            "Speed: 0.4ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 motorcycle, 32.6ms\n",
            "Speed: 0.4ms preprocess, 32.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 motorcycle, 34.8ms\n",
            "Speed: 0.3ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 motorcycle, 32.7ms\n",
            "Speed: 0.4ms preprocess, 32.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 motorcycle, 33.8ms\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.0ms\n",
            "Speed: 0.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 34.8ms\n",
            "Speed: 0.4ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 motorcycle, 33.2ms\n",
            "Speed: 0.5ms preprocess, 33.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 motorcycle, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.6ms\n",
            "Speed: 0.6ms preprocess, 33.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 33.9ms\n",
            "Speed: 0.6ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 31.9ms\n",
            "Speed: 0.5ms preprocess, 31.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 32.7ms\n",
            "Speed: 0.5ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 32.4ms\n",
            "Speed: 0.5ms preprocess, 32.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 32.1ms\n",
            "Speed: 0.4ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 32.2ms\n",
            "Speed: 0.4ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 motorcycle, 33.2ms\n",
            "Speed: 0.4ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.1ms\n",
            "Speed: 0.4ms preprocess, 33.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.8ms\n",
            "Speed: 0.6ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 12 cars, 33.5ms\n",
            "Speed: 0.4ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 34.1ms\n",
            "Speed: 0.4ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 14 cars, 34.4ms\n",
            "Speed: 0.4ms preprocess, 34.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 buss, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 buss, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 buss, 32.4ms\n",
            "Speed: 0.4ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 3 buss, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 buss, 32.8ms\n",
            "Speed: 0.5ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 buss, 32.9ms\n",
            "Speed: 0.4ms preprocess, 32.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 buss, 33.0ms\n",
            "Speed: 0.4ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 13 cars, 32.3ms\n",
            "Speed: 0.4ms preprocess, 32.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vNl0gVRBVUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}